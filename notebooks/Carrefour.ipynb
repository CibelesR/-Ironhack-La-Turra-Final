{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carrefour\n",
    "\n",
    "#### Como nos ha ido bien con día vamos a intenter scrapear la web de carrefour, que posiblemente tenga más artículos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from lxml import html\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repetimos el proceso del scraping de día para carrefour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Natalio/miniconda3/envs/pfironhack_env/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (0,24,25,26,28,44,49) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/Natalio/Desktop/Cibeles/Ironhack/Proyecto_Final/Recursos/en.openfoodfacts.org.products.csv', sep='\\t')\n",
    "codes = df['code'].to_list()\n",
    "barcodes = [i for i in codes if len(str(i)) == 13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barcodes = ['5449000000996','0','0000000000208']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "barcodes = ['5449000000996']\n",
    "\n",
    "for barcode in barcodes:\n",
    "    url = 'https://www.carrefour.es/?q=' + barcode\n",
    "    html = requests.get(url).content\n",
    "    bs = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "    searchingprice = bs.find_all('strong', {'class':'ebx-result-price__value'})\n",
    "    print(searchingprice)\n",
    "    \n",
    "    searchingpricerperkg = bs.find_all('span', {'class':'ebx-result__quantity ebx-result-quantity'})\n",
    "    print(searchingpricerperkg)\n",
    "    \n",
    "        #price = str(re.findall('.*(\\d+\\,\\d+)\\s\\€', str(searchingprice))[0])\n",
    "        #dfprice.append(price)\n",
    "\n",
    "        #searchingpricerperkg = bs.find_all('p', {'class':'pricePerKilogram'})\n",
    "        #pricekg = str(re.findall('.*(\\d+\\,\\d+)\\s\\€', str(searchingpricerperkg))[0])\n",
    "        #dfpricekg.append(pricekg)\n",
    "\n",
    "#dfprice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<span class=\"\">1,97 €/l</span>    dfprice.append(price)\n",
    "\n",
    "        searchingpricerperkg = bs.find_all('p', {'class':'pricePerKilogram'})\n",
    "        pricekg = str(re.findall('.*(\\d+\\,\\d+)\\s\\€', str(searchingpricerperkg))[0])\n",
    "        dfpricekg.append(pricekg)\n",
    "    \n",
    "    except:\n",
    "        dfprice.append('no data')\n",
    "        dfpricekg.append('no data')\n",
    "        \n",
    "result = list(zip(barcodes, dfprice, dfpricekg))\n",
    "\n",
    "df = pd.DataFrame(result, columns = ['code','price','pricekg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapinginfo(barcodes):\n",
    "    dfprice = []\n",
    "    dfpricekg = []\n",
    "    for barcode in barcodes:\n",
    "        url = 'https://www.dia.es/compra-online/search?text=' + barcode + '&x=0&y=0'\n",
    "        html = requests.get(url).content\n",
    "        bs = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "        try:\n",
    "            searchingprice = bs.find_all('p', {'class':'price'})\n",
    "            price = str(re.findall('.*(\\d+\\,\\d+)\\s\\€', str(searchingprice))[0])\n",
    "            dfprice.append(price)\n",
    "\n",
    "            searchingpricerperkg = bs.find_all('p', {'class':'pricePerKilogram'})\n",
    "            pricekg = str(re.findall('.*(\\d+\\,\\d+)\\s\\€', str(searchingpricerperkg))[0])\n",
    "            dfpricekg.append(pricekg)\n",
    "    \n",
    "        except:\n",
    "            dfprice.append('no data')\n",
    "            dfpricekg.append('no data')\n",
    "        \n",
    "    result = list(zip(barcodes, dfprice, dfpricekg))\n",
    "\n",
    "    df = pd.DataFrame(result, columns = ['code','price','pricekg'])\n",
    "    return df\n",
    "\n",
    "scrapinginfo(barcodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.carrefour.es/?q=5449000000996\n"
     ]
    }
   ],
   "source": [
    "print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pfironhack_env] *",
   "language": "python",
   "name": "conda-env-pfironhack_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
